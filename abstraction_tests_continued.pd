#N canvas 4 70 2309 1332 16;
#X obj 13 40 bng 23 250 50 0 empty empty empty 0 -12 0 16 #fcfcfc #000000 #000000;
#X obj 13 68 f \$0;
#X obj 13 106 s \$0_ns;
#N canvas 137 158 675 1035 arrays 0;
#X obj 23 19 array define \$0_a 4;
#X obj 23 56 array define \$0_b 4;
#X obj 24 93 array define \$0_c 4;
#X obj 25 135 array define \$0_d 4;
#X obj 25 193 array define \$0_weight_1 1;
#X obj 24 376 array define \$0_bias_1 1;
#X obj 26 594 array define \$0_activation_output_1 4;
#X obj 27 630 array define \$0_linear_output_1 4;
#X obj 25 224 array define \$0_weight_2 2;
#X obj 28 745 array define \$0_X 4;
#X obj 28 781 array define \$0_Y 4;
#X obj 27 842 array define \$0_dz_1 4;
#X obj 28 811 array define \$0_y_hat 4;
#X obj 25 254 array define \$0_d_weight_2 2;
#X obj 24 406 array define \$0_d_bias_1 1;
#X obj 213 19 array define \$0_da 4;
#X obj 213 56 array define \$0_dbee 4;
#X obj 26 664 array define \$0_activation_output_2 4;
#X obj 27 700 array define \$0_linear_output_2 4;
#X obj 24 434 array define \$0_bias_2 1;
#X obj 24 464 array define \$0_d_bias_2 1;
#X obj 27 285 array define \$0_weight_3 1;
#X obj 27 319 array define \$0_d_weight_3 1;
#X obj 27 872 array define \$0_dz_2 4;
#X restore 13 137 pd arrays;
#X obj 93 106 print name_space;
#X obj 13 6 loadbang;
#N canvas 1139 123 1230 1364 initialize_test_data 0;
#X obj 37 1019 array set;
#X msg 107 154 symbol a;
#X msg 187 243 symbol b;
#X msg 259 341 symbol c;
#X msg 360 420 symbol d;
#X msg 385 521 symbol weight_1;
#X msg 438 612 symbol bias_1;
#X msg 37 155 1 2 3 4;
#X msg 114 245 2 3 4 5;
#X msg 187 342 3 4 5 6;
#X msg 286 423 4 5 6 7;
#X msg 344 522 0.2;
#X msg 393 613 0.3;
#X obj 107 187 d_0;
#X obj 150 186 r \$0_ns;
#X obj 187 277 d_0;
#X obj 230 276 r \$0_ns;
#X obj 259 377 d_0;
#X obj 302 376 r \$0_ns;
#X obj 360 457 d_0;
#X obj 403 456 r \$0_ns;
#X obj 385 557 d_0;
#X obj 428 556 r \$0_ns;
#X obj 439 647 d_0;
#X obj 482 646 r \$0_ns;
#X obj 37 13 loadbang;
#X msg 116 13 bang;
#X obj 505 735 d_0;
#X obj 548 734 r \$0_ns;
#X msg 504 700 symbol weight_2;
#X msg 419 701 0.02 0.03;
#X obj 504 816 d_0;
#X obj 547 815 r \$0_ns;
#X msg 434 784 5 6 7 8;
#X obj 552 894 d_0;
#X obj 595 893 r \$0_ns;
#X msg 475 862 9 11 2 6;
#X msg 552 861 symbol Y;
#X msg 504 783 symbol y_hat;
#X obj 573 973 d_0;
#X obj 616 972 r \$0_ns;
#X msg 496 941 0.333;
#X msg 573 940 symbol weight_3;
#X obj 573 1063 d_0;
#X obj 616 1062 r \$0_ns;
#X msg 574 1030 symbol bias_2;
#X msg 496 1031 -0.2;
#X obj 37 51 t b b b b b b b b b b b b b b b b b b b b b b, f 114;
#X connect 1 0 13 0;
#X connect 2 0 15 0;
#X connect 3 0 17 0;
#X connect 4 0 19 0;
#X connect 5 0 21 0;
#X connect 6 0 23 0;
#X connect 7 0 0 0;
#X connect 8 0 0 0;
#X connect 9 0 0 0;
#X connect 10 0 0 0;
#X connect 11 0 0 0;
#X connect 12 0 0 0;
#X connect 13 0 0 2;
#X connect 14 0 13 1;
#X connect 15 0 0 2;
#X connect 16 0 15 1;
#X connect 17 0 0 2;
#X connect 18 0 17 1;
#X connect 19 0 0 2;
#X connect 20 0 19 1;
#X connect 21 0 0 2;
#X connect 22 0 21 1;
#X connect 23 0 0 2;
#X connect 24 0 23 1;
#X connect 25 0 47 0;
#X connect 26 0 47 0;
#X connect 27 0 0 2;
#X connect 28 0 27 1;
#X connect 29 0 27 0;
#X connect 30 0 0 0;
#X connect 31 0 0 2;
#X connect 32 0 31 1;
#X connect 33 0 0 0;
#X connect 34 0 0 2;
#X connect 35 0 34 1;
#X connect 36 0 0 0;
#X connect 37 0 34 0;
#X connect 38 0 31 0;
#X connect 39 0 0 2;
#X connect 40 0 39 1;
#X connect 41 0 0 0;
#X connect 42 0 39 0;
#X connect 43 0 0 2;
#X connect 44 0 43 1;
#X connect 45 0 43 0;
#X connect 46 0 0 0;
#X connect 47 0 7 0;
#X connect 47 1 1 0;
#X connect 47 2 8 0;
#X connect 47 3 2 0;
#X connect 47 4 9 0;
#X connect 47 5 3 0;
#X connect 47 6 10 0;
#X connect 47 7 4 0;
#X connect 47 8 11 0;
#X connect 47 9 5 0;
#X connect 47 10 12 0;
#X connect 47 11 6 0;
#X connect 47 12 30 0;
#X connect 47 13 29 0;
#X connect 47 14 33 0;
#X connect 47 15 38 0;
#X connect 47 16 36 0;
#X connect 47 17 37 0;
#X connect 47 18 41 0;
#X connect 47 19 42 0;
#X connect 47 20 46 0;
#X connect 47 21 45 0;
#X restore 12 170 pd initialize_test_data;
#X obj 347 -1 cnv 23 800 500 empty empty empty 20 12 0 16 #e0e0e0 #404040 0;
#X text 355 -1 //testing nn.dz_mse \; dL/dA (outer layer) = (A - Y) \; g'(Z) = 1 \; dZ = dA x g'(Z) = (A - Y);
#X obj 360 129 nn.dz_mse y_hat Y dz_1;
#X msg 360 91 bang;
#X obj 554 128 r \$0_ns;
#X obj 360 199 nn.array_cycle y_hat;
#X obj 536 199 r \$0_ns;
#X floatatom 360 234 5 0 0 0 - - - 0;
#X msg 360 163 bang;
#X obj 360 261 nn.array_read Y;
#X obj 502 260 r \$0_ns;
#X obj 590 259 nn.array_read dz_1;
#X obj 752 259 r \$0_ns;
#X obj 360 319 f;
#X floatatom 517 230 5 0 0 0 - - - 0;
#X floatatom 477 303 5 0 0 0 - - - 0;
#X floatatom 731 303 5 0 0 0 - - - 0;
#X obj 435 409 print stored equals calculated;
#X obj 435 381 expr $f2 - $f3 == $f1;
#X text 407 161 // click!;
#X text 648 4 // NOTE: the dz for each z indicates how much a tiny change to the linear output would affect the loss. When the linear output is higher than the Y value in a positive direction \, dZ will be positive. This makes it intuitively clear why parameter derivates are _subtracted_ from params when updating them.;
#X obj 347 509 cnv 23 800 800 empty empty empty 20 12 0 16 #e0e0e0 #404040 0;
#X text 373 514 // testing nn.dw_1x1 \; dW^[l] = 1/m x dZ^[l]A^[l-1]T;
#X obj 621 846 r \$0_ns;
#X msg 378 814 bang;
#X obj 378 846 nn.dw_1x1 dz_1 a d_weight_2 0;
#X text 634 512 // NOTE: implemented without matrix operations in Pd \, each of a layer's weights is associated with a feature from the previous layer A[l-1]. If the previous layer had 2 features \, the current layer's weights will have 2 columns. The nn.dw_1x1 abstraction sets dW for one column of one node.;
#X text 634 628 // NOTE: the formula is using the chain rule of calculus. The amount that changes to a weight will affect the loss is found by multiplying how much changes to the outer function (z) will affect the loss by how much changes to w affect the output of z.;
#X obj 621 880 r \$0_ns;
#X obj 378 880 nn.dw_1x1 dz_1 b d_weight_2 1;
#X text 640 735 // NOTE: the nn.dw_1x1 function is called twice because the (hypothetical) neuron has two input features (a \, b). It follows that weight_2 and d_weight_2 have the shape (1 \, 2);
#X obj 378 955 nn.array_cycle d_weight_2;
#X obj 378 983 pack f f, f 25;
#X obj 594 956 r \$0_ns;
#X msg 376 922 bang;
#X msg 378 1011 dw at index \$1: \$2;
#X obj 378 1039 print;
#X text 635 810 // NOTE: this test depends on dz_1 from the previous panel;
#X obj 1157 -1 cnv 23 800 800 empty empty empty 20 12 0 16 #e0e0e0 #404040 0;
#X text 1209 0 // nn.dw_1x1 test continued;
#X obj 1177 220 nn.element_wise_product;
#X obj 1378 133 d_0;
#X obj 1418 133 r \$0_ns;
#X obj 1378 161 t s b s;
#X msg 1378 105 symbol a;
#X obj 1267 133 d_0;
#X obj 1307 133 r \$0_ns;
#X obj 1404 220 array size;
#X msg 1267 105 symbol dz_1;
#X obj 1383 286 /;
#X obj 1502 228 nn.array_read d_weight_2;
#X msg 1502 190 0;
#X obj 1383 323 ==;
#X obj 1383 379 print saved dw equals calculated;
#X msg 1177 28 bang;
#X obj 1177 56 t b b b b, f 41;
#X obj 1712 228 r \$0_ns;
#X obj 1177 580 nn.element_wise_product;
#X obj 1378 493 d_0;
#X obj 1418 493 r \$0_ns;
#X obj 1378 521 t s b s;
#X obj 1267 493 d_0;
#X obj 1307 493 r \$0_ns;
#X obj 1404 580 array size;
#X msg 1267 465 symbol dz_1;
#X obj 1383 646 /;
#X obj 1502 588 nn.array_read d_weight_2;
#X obj 1383 683 ==;
#X obj 1383 739 print saved dw equals calculated;
#X msg 1177 388 bang;
#X obj 1177 416 t b b b b, f 41;
#X obj 1712 588 r \$0_ns;
#X msg 1378 465 symbol b;
#X msg 1502 550 1;
#X obj 1156 808 cnv 23 800 330 empty empty empty 20 12 0 16 #e0e0e0 #404040 0;
#X obj 1281 990 d_0;
#X obj 1321 990 r \$0_ns;
#X msg 1281 962 symbol a;
#X obj 1394 991 d_0;
#X obj 1434 991 r \$0_ns;
#X msg 1395 961 symbol b;
#X text 1193 813 // test nn.element_wise_product \; a = 1 2 3 4 \; b = 2 3 4 5 \; 1 x 2 + 2 x 3 + 3 x 4 + 4 x 5 = 40;
#X obj 1191 1023 nn.element_wise_product;
#X msg 1191 900 bang;
#X obj 1191 928 t b b b, f 26;
#X obj 1191 1051 == 40;
#X obj 1191 1079 print element wise product correct;
#X obj 1967 -2 cnv 23 800 880 empty empty empty 20 12 0 16 #e0e0e0 #404040 0;
#X text 2005 398 // test nn.db_1x1 \; db^[l] = 1/m x sum(dZ^[l]);
#X text 1981 4 // NOTE: the formula uses the chain rule of calculus. The derivative of z (the outer function) with respect to b is 1 \, so only dZ has an effect on the loss.;
#X text 1982 73 // NOTE: this test depends on the value of dz_1 that's been previously calculated;
#X obj 2031 163 nn.db_1x1 dz_1 d_bias_1;
#X obj 2231 163 r \$0_ns;
#X obj 2031 337 d_0;
#X obj 2071 337 r \$0_ns;
#X msg 2031 309 symbol dz_1;
#X obj 2158 340 nn.array_read d_bias_1;
#X obj 2349 340 r \$0_ns;
#X msg 2158 309 0;
#X obj 2082 435 array size;
#X obj 2031 365 t b s b s;
#X obj 1984 435 array sum;
#X obj 2061 490 /;
#X obj 2061 518 ==;
#X msg 2031 128 bang;
#X obj 2031 191 t b b;
#X obj 2332 375 t f f;
#X obj 2061 546 print calculated db = stored;
#X obj 2369 415 print stored db;
#X text 1988 597 // manually confirm:;
#X obj 1982 751 array get;
#X obj 2051 716 d_0;
#X obj 2091 716 r \$0_ns;
#X msg 2051 688 symbol dz_1;
#X msg 1982 626 bang;
#X obj 1982 779 print dz_1;
#X obj 1982 654 t b b;
#X text 2500 416 // stored db: -0.5;
#X text 1980 824 // dz_1: -4 -5 5 2 \; (-4 + -5 + 5 + 2) / 4 = -0.5;
#X obj 1965 886 cnv 23 800 420 empty empty empty 20 12 0 16 #e0e0e0 #404040 0;
#X text 2005 888 // test nn.da_row \; dA^[l-1] = W^[l]T dZ^[l];
#X text 1977 939 // NOTE: using the chain rule of calculus. The outer function for a previous layer's activation is the current layer's z function. A previous layer's activiation affects the loss based on how much it affects the outer functino it's called in (dZ/dA^[l-1] = W^[l]) and how much the outer function (z) affects the loss (dL/dZ).;
#X text 1982 1072 // NOTE: a layer's weights have the shape (n_l \, n_l_prev). In the Pd implementation with 1D arrays \, each neuron's weights are a separate array with the shape (1 \, n_l_prev). A layer will have 1 weight array for each of its neurons. The nn.da_row function name is reasonably accurate. The weight index argument corresponds to the row of the a_previous da that's being calculated. A particular activation array from the previous layer is associated with the index of a weight of the current layer.;
#X obj 2776 -6 cnv 23 800 950 empty empty empty 20 12 0 16 #e0e0e0 #404040 0;
#X text 2801 -4 // nn.da_row test continued... NOTE: this test uses the previously calculated dz_1 array. It's also using the (awkwardly named) da and dbee arrays;
#X obj 2825 118 nn.da_row weight_2 dz_1 da 0;
#X obj 3066 118 r \$0_ns;
#X obj 3084 178 r \$0_ns;
#X obj 2825 178 nn.da_row weight_2 dz_1 dbee 1;
#X msg 2825 67 bang;
#X obj 2977 364 r \$0_ns;
#X obj 2825 412 f;
#X obj 3219 364 r \$0_ns;
#X msg 3294 329 0;
#X obj 3195 411 *;
#X msg 2825 235 bang;
#X obj 2825 263 t b b;
#X obj 2825 364 nn.array_cycle da;
#X obj 3054 365 nn.array_read dz_1;
#X obj 3095 495 ==;
#X obj 3095 553 print calculated da equals stored;
#X obj 2958 411 print stored da;
#X obj 3294 363 nn.array_read weight_2;
#X obj 3487 342 r \$0_ns;
#X obj 3246 412 print calculated dz;
#X obj 2997 694 r \$0_ns;
#X obj 2825 742 f;
#X obj 3239 694 r \$0_ns;
#X obj 3215 741 *;
#X msg 2825 565 bang;
#X obj 2825 593 t b b;
#X obj 3074 695 nn.array_read dz_1;
#X obj 3095 825 ==;
#X obj 3095 883 print calculated da equals stored;
#X obj 2974 741 print stored da;
#X obj 3314 693 nn.array_read weight_2;
#X obj 3507 692 r \$0_ns;
#X obj 3266 742 print calculated dz;
#X obj 2825 694 nn.array_cycle dbee;
#X msg 3314 659 1;
#X text 3053 216 // for reference \, I found a bug in the function when doing this. I was loading the index arg with [loadbang] which was super unreliable if it ever worked at all.;
#X obj 3588 -5 cnv 23 800 1300 empty empty empty 20 12 0 16 #e0e0e0 #404040 0;
#X text 3622 9 // test nn.dz_for_g \; dZ^[l] = dA^[l] x g^[l]'(z);
#X text 3610 74 // generate the test data:;
#X obj 3879 9 bng 23 250 50 0 empty empty empty 0 -12 0 16 #fcfcfc #000000 #000000;
#X obj 3879 37 f \$0;
#X obj 3879 75 s \$0_ns;
#X msg 3612 128 4;
#X obj 3612 156 until;
#X obj 3612 184 nn.array_cycle a, f 24;
#X obj 3820 184 r \$0_ns;
#X obj 3612 242 nn.neuron_1 weight_1 bias_1 activation_output_1 linear_output_1 tanh, f 48;
#X obj 4010 241 r \$0_ns;
#X obj 4010 321 r \$0_ns;
#X obj 3802 392 print y_hat;
#X obj 3612 322 nn.neuron_1 weight_3 bias_2 activation_output_2 linear_output_2 linear, f 48;
#X text 3633 293 // layer L;
#X text 3620 213 // layer L-1;
#X msg 3620 436 bang;
#X obj 3921 474 r \$0_ns;
#X obj 4012 522 r \$0_ns;
#X obj 3620 521 nn.dw_1x1 dz_2 activation_output_1 d_weight_3 0;
#X obj 3820 567 r \$0_ns;
#X obj 3620 567 nn.db_1x1 dz_2 d_bias_2;
#X obj 3887 619 r \$0_ns;
#X text 3705 436 // backprop layer L;
#X text 3697 656 // backprop layer L-1;
#X obj 4117 687 r \$0_ns;
#X obj 3620 619 nn.da_row weight_3 dz_2 da 0;
#X obj 3620 687 nn.dz_for_g da linear_output_1 activation_output_1 dz_1 tanh;
#X obj 3620 474 nn.dz_mse activation_output_2 Y dz_2;
#X msg 3620 733 4;
#X obj 3620 761 until;
#X obj 3620 789 nn.array_cycle da;
#X obj 3781 789 r \$0_ns;
#X obj 3620 867 nn.array_read activation_output_1;
#X obj 3908 867 r \$0_ns;
#X obj 3881 925 expr 1 - $f1 * $f1;
#X obj 3732 977 *;
#X obj 3774 896 r \$0_ns;
#X obj 3620 938 print stored dz;
#X obj 3732 1024 print calculated dz;
#X obj 3620 895 nn.array_read dz_1;
#X connect 0 0 1 0;
#X connect 1 0 2 0;
#X connect 1 0 4 0;
#X connect 5 0 0 0;
#X connect 10 0 9 0;
#X connect 11 0 9 1;
#X connect 12 0 14 0;
#X connect 12 1 21 0;
#X connect 13 0 12 2;
#X connect 14 0 16 0;
#X connect 15 0 12 0;
#X connect 16 0 20 0;
#X connect 16 1 22 0;
#X connect 17 0 16 1;
#X connect 18 1 23 0;
#X connect 19 0 18 1;
#X connect 20 0 18 0;
#X connect 21 0 25 1;
#X connect 22 0 25 2;
#X connect 23 0 25 0;
#X connect 25 0 24 0;
#X connect 30 0 32 1;
#X connect 31 0 32 0;
#X connect 32 0 36 0;
#X connect 35 0 36 1;
#X connect 38 0 39 0;
#X connect 38 1 39 1;
#X connect 39 0 42 0;
#X connect 40 0 38 2;
#X connect 41 0 38 0;
#X connect 42 0 43 0;
#X connect 47 0 56 0;
#X connect 48 0 50 0;
#X connect 49 0 48 1;
#X connect 50 0 47 2;
#X connect 50 1 54 0;
#X connect 50 2 54 1;
#X connect 51 0 48 0;
#X connect 52 0 47 1;
#X connect 53 0 52 1;
#X connect 54 0 56 1;
#X connect 55 0 52 0;
#X connect 56 0 59 0;
#X connect 57 1 59 1;
#X connect 58 0 57 0;
#X connect 59 0 60 0;
#X connect 61 0 62 0;
#X connect 62 0 47 0;
#X connect 62 1 55 0;
#X connect 62 2 51 0;
#X connect 62 3 58 0;
#X connect 63 0 57 1;
#X connect 64 0 72 0;
#X connect 65 0 67 0;
#X connect 66 0 65 1;
#X connect 67 0 64 2;
#X connect 67 1 70 0;
#X connect 67 2 70 1;
#X connect 68 0 64 1;
#X connect 69 0 68 1;
#X connect 70 0 72 1;
#X connect 71 0 68 0;
#X connect 72 0 74 0;
#X connect 73 1 74 1;
#X connect 74 0 75 0;
#X connect 76 0 77 0;
#X connect 77 0 64 0;
#X connect 77 1 71 0;
#X connect 77 2 79 0;
#X connect 77 3 80 0;
#X connect 78 0 73 1;
#X connect 79 0 65 0;
#X connect 80 0 73 0;
#X connect 82 0 89 1;
#X connect 83 0 82 1;
#X connect 84 0 82 0;
#X connect 85 0 89 2;
#X connect 86 0 85 1;
#X connect 87 0 85 0;
#X connect 89 0 92 0;
#X connect 90 0 91 0;
#X connect 91 0 89 0;
#X connect 91 1 84 0;
#X connect 91 2 87 0;
#X connect 92 0 93 0;
#X connect 98 0 112 0;
#X connect 99 0 98 1;
#X connect 100 0 107 0;
#X connect 101 0 100 1;
#X connect 102 0 100 0;
#X connect 103 1 113 0;
#X connect 104 0 103 1;
#X connect 105 0 103 0;
#X connect 106 0 109 1;
#X connect 107 0 108 0;
#X connect 107 1 108 2;
#X connect 107 2 106 0;
#X connect 107 3 106 1;
#X connect 108 0 109 0;
#X connect 109 0 110 0;
#X connect 110 0 114 0;
#X connect 111 0 98 0;
#X connect 112 0 102 0;
#X connect 112 1 105 0;
#X connect 113 0 110 1;
#X connect 113 1 115 0;
#X connect 117 0 122 0;
#X connect 118 0 117 2;
#X connect 119 0 118 1;
#X connect 120 0 118 0;
#X connect 121 0 123 0;
#X connect 123 0 117 0;
#X connect 123 1 120 0;
#X connect 132 0 135 0;
#X connect 133 0 132 1;
#X connect 134 0 135 1;
#X connect 136 0 132 0;
#X connect 137 0 144 2;
#X connect 138 0 145 0;
#X connect 139 0 145 1;
#X connect 140 0 149 0;
#X connect 141 0 146 0;
#X connect 142 0 143 0;
#X connect 143 0 144 0;
#X connect 143 1 140 0;
#X connect 144 0 138 0;
#X connect 144 1 146 1;
#X connect 144 1 148 0;
#X connect 145 1 141 0;
#X connect 145 1 151 0;
#X connect 146 0 147 0;
#X connect 149 1 141 1;
#X connect 150 0 149 1;
#X connect 152 0 165 2;
#X connect 153 0 158 0;
#X connect 154 0 158 1;
#X connect 155 0 159 0;
#X connect 156 0 157 0;
#X connect 157 0 165 0;
#X connect 157 1 166 0;
#X connect 158 1 155 0;
#X connect 158 1 164 0;
#X connect 159 0 160 0;
#X connect 162 1 155 1;
#X connect 163 0 162 1;
#X connect 165 0 153 0;
#X connect 165 1 159 1;
#X connect 165 1 161 0;
#X connect 166 0 162 0;
#X connect 171 0 172 0;
#X connect 172 0 173 0;
#X connect 174 0 175 0;
#X connect 175 0 176 0;
#X connect 176 0 178 0;
#X connect 176 1 178 1;
#X connect 177 0 176 2;
#X connect 178 0 182 0;
#X connect 178 1 182 1;
#X connect 179 0 178 2;
#X connect 180 0 182 2;
#X connect 182 1 181 0;
#X connect 185 0 197 0;
#X connect 186 0 197 1;
#X connect 187 0 188 1;
#X connect 188 0 190 0;
#X connect 189 0 190 1;
#X connect 190 0 195 0;
#X connect 191 0 195 1;
#X connect 194 0 196 1;
#X connect 195 0 196 0;
#X connect 197 0 188 0;
#X connect 198 0 199 0;
#X connect 199 0 200 0;
#X connect 200 0 202 0;
#X connect 200 1 205 1;
#X connect 201 0 200 2;
#X connect 202 0 209 0;
#X connect 202 1 204 0;
#X connect 203 0 202 1;
#X connect 204 0 205 0;
#X connect 205 0 208 0;
#X connect 206 0 209 1;
#X connect 209 1 207 0;
